---
title: "IDS investigation worksheet by Xiufeng"
author: "by 4677:Xiufeng Zhu"
date: "`2025.10.28"
output: html_document
editor_options: 
  markdown: 
    wrap: sentence
---

**Note:** You can use this file as you 'working document' where you can try out various investigation ideas and keep notes about your findings.
How you use and structure this file is up to you.
It is recommended that you keep notes about what you are investigating and what you find as this will make the process of creating your presentation and report easier.
Please note that you *do not* need to submit this file as part of your group project.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load-lib, message = FALSE}
options(repos = c(CRAN = "https://cloud.r-project.org"))
library(tidyverse)
# Add any other libraries here
library(dplyr)
library(tidyr)


```

Analysis Steps Load the Dataset:

Imported from the CSV file.
Summary statistics reviewed.
Data Cleaning:

Handled missing values.
Removed features with excessive missing data.
Standardized data for regression.
Exploratory Data Analysis (EDA):

Visualized relationships between features and crime rates.
Identified patterns and key features.
Regression Modeling:

Linear Regression: Modeled continuous crime rates based on features.
Logistic Regression: Converted the crime rate into binary classification (e.g., high/low) for logistic analysis.
Evaluation:

Analyzed model performance metrics (e.g., accuracy, R-squared, confusion matrix).

Classic usage scenarios: In the field of crime analysis and prediction, the classic application scenarios of the Communities and Crime dataset mainly focus on predicting the crime rate of communities through regression models.
Researchers utilize the socio-economic, law enforcement, and demographic data in this dataset to identify the key factors influencing the crime rate and make predictions.
This analysis not only helps understand the drivers of the crime rate but also provides data support for policymakers to formulate more effective prevention strategies.

Solve academic problems: The Communities and Crime dataset addresses a fundamental issue in criminology research: how to quantify and predict the crime rate in communities.
By integrating multi-dimensional socio-economic and demographic data, this dataset provides a rich resource for the academic community to explore the complex relationships between crime rates and various social factors.
This not only drives the research on crime prediction models but also offers scientific basis for decision-making in the fields of social policies and public safety.

Practical application: In practical applications, the Communities and Crime dataset is widely used in urban planning and public safety management.
For instance, local governments and law enforcement agencies can utilize the analysis results of this dataset to optimize resource allocation and enhance community security.
Additionally, non-profit organizations and community groups can also leverage these data to design targeted social intervention programs in order to reduce crime rates and improve the community environment.



| Type | What to Add                                | Why It Improves Your Project                              |
| ---- | ------------------------------------------ | --------------------------------------------------------- |
| 1️⃣  | Correlation heatmap                        | Visualize variable relationships clearly                  |
| 2️⃣  | Distribution plots                         | Show how target and predictors vary                       |
| 3️⃣  | Variable selection (feature reduction)     | Simplify model and improve interpretability               |
| 4️⃣  | Cross-validation                           | Make model evaluation more robust                         |
| 5️⃣  | Residual analysis                          | Check model errors for bias                               |
| 6️⃣  | Map or geographic visualization (optional) | Show crime rates per area (if you find state/county info) |
| 7️⃣  | Model comparison plot                      | Visually compare models                                   |
| 8️⃣  | Deeper ethics discussion                   | Shows awareness of real-world implications                |

> **Ethical Considerations**  
> The Communities and Crime dataset contains sensitive attributes such as race, income, and family structure.  
> These variables can reflect systemic inequalities and should be treated carefully:
> - Avoid using models like these for **individual prediction or policing**.  
> - Be aware of **bias amplification**: if biased data (e.g., due to unequal policing) is used to train a model, predictions will also be biased.  
> - Focus on **understanding community-level patterns** and informing equitable policy decisions rather than punitive actions.  
>  
> Ethical data science means asking not just *“Can we predict it?”* but also *“Should we?”*.



```{r load-data}
library(tidyverse)

options(repos = c(CRAN = "https://cloud.r-project.org"))

# Load column names
names_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.names"
name_lines <- readLines(names_url)
name_lines <- name_lines[grepl("^@attribute", name_lines)]
col_names <- gsub("^@attribute\\s+", "", name_lines)
col_names <- sub("\\s+.*$", "", col_names)
col_names <- col_names[col_names != ""]

# Load dataset
data_url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data"
crime <- read.csv(data_url, header = FALSE, na.strings = "?", col.names = col_names)

# Clean dataset
crime <- crime %>%
  select(-state, -county, -community, -communityname, -fold)

# Replace missing values with column means
library(dplyr)

data_clean <- crime %>%
  mutate(across(where(is.numeric),
                ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))

# Print the new shape of the cleaned data
summary(data_clean)
cat("Data cleaned. Shape:", nrow(data_clean), "rows and", ncol(data_clean), "columns\n")

library(corrplot)

# Compute correlations among numeric columns
crime_num <- data_clean %>% select(where(is.numeric))
corr_matrix <- cor(crime_num, use = "complete.obs")

# Plot heatmap for top correlated features
corrplot(corr_matrix, type = "lower", tl.cex = 0.6, tl.col = "black")

# Target Variable Distribution
ggplot(data_clean, aes(x = ViolentCrimesPerPop)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "white") +
  labs(title = "Distribution of Violent Crime Rate",
       x = "Violent Crimes per Population", y = "Frequency")

ggplot(data_clean, aes(x = PctPopUnderPov, y = ViolentCrimesPerPop)) +
geom_point(alpha = 0.5, color = "purple") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Violent Crime vs Poverty", x = "Poverty (%)", y = "Violent Crime Rate")

library(caret)      
library(randomForest) 

set.seed(123)
train_index <- createDataPartition(data_clean$ViolentCrimesPerPop, p = 0.8, list = FALSE)
train <- data_clean[train_index, ]
test  <- data_clean[-train_index, ]

# Correlation with target
corrs <- sapply(data_clean, function(x) cor(x, data_clean$ViolentCrimesPerPop, use = "complete.obs"))
head(sort(corrs, decreasing = TRUE), 10)

summary(data_clean$ViolentCrimesPerPop)

# Check a few relationships
plot(data_clean$medIncome, data_clean$ViolentCrimesPerPop,
     main = "Crime vs Median Income",
     xlab = "Median Income", ylab = "Violent Crime Rate")

plot(data_clean$pctWWage, data_clean$ViolentCrimesPerPop,
     main = "Crime vs WWage",
     xlab = "WWage %", ylab = "Violent Crime Rate")

# Build two models

# (a) Linear Regression
lm_model <- lm(ViolentCrimesPerPop ~ ., data = train)
lm_pred <- predict(lm_model, newdata = test)

# (b) Random Forest
rf_model <- randomForest(ViolentCrimesPerPop ~ ., data = train, ntree = 150)
rf_pred <- predict(rf_model, newdata = test)

# Evaluate models
# Calculate R-squared (how well model fits) and RMSE (error)
lm_r2 <- cor(lm_pred, test$ViolentCrimesPerPop)^2
rf_r2 <- cor(rf_pred, test$ViolentCrimesPerPop)^2

lm_rmse <- sqrt(mean((lm_pred - test$ViolentCrimesPerPop)^2))
rf_rmse <- sqrt(mean((rf_pred - test$ViolentCrimesPerPop)^2))

cat("Linear Regression: R2 =", lm_r2, " RMSE =", lm_rmse, "\n")
cat("Random Forest: R2 =", rf_r2, " RMSE =", rf_rmse, "\n")


# Visualize predictions 
results <- data.frame(
  Actual = test$ViolentCrimesPerPop,
  Predicted = rf_pred
)

ggplot(results, aes(x = Actual, y = Predicted)) +
  geom_point(color = "blue", alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Random Forest Predictions vs Actual",
       x = "Actual Violent Crime Rate",
       y = "Predicted Crime Rate")

# Feature importance (which factors matter most) 
varImpPlot(rf_model, n.var = 10, main = "Most Important Features")

# Residual Analysis (Model Diagnostics)
residuals_rf <- test$ViolentCrimesPerPop - rf_pred

ggplot(data.frame(residuals_rf), aes(x = residuals_rf)) +
  geom_histogram(bins = 30, fill = "darkorange", color = "white") +
  labs(title = "Residual Distribution (Random Forest)",
       x = "Residuals", y = "Count")

library(plotly)


p <- ggplot(crime, aes(x = PctPopUnderPov, y = ViolentCrimesPerPop)) +
  geom_point(alpha = 0.6, color = "purple") +
  labs(title = "Interactive: Poverty vs Violent Crime",
       x = "Poverty (%)", y = "Violent Crime Rate")


ggplotly(p)




```
